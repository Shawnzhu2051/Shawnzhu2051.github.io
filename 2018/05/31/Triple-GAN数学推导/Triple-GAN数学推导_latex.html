<hr>
<p>title: Triple GAN数学推导<br>date: 2018-05-31 10:51:24<br>tags: “机器学习”</p>
<h2 id="mathjax-true"><a href="#mathjax-true" class="headerlink" title="mathjax: true"></a>mathjax: true</h2><p>Triple GAN（原文链接：<a href="https://arxiv.org/abs/1703.02291">https://arxiv.org/abs/1703.02291</a> ） 是NIPS 2017中的一篇跟GAN有关的文章，是清华大学Zhu Jun老师团队的研究成果。因为其中涉及到半监督学习的部分对我手上的课题有一定的指导作用，所以认真地钻研了下这篇文章。下面是我自己翻译的摘要：</p>
<!-- more -->
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>对抗生成网络（GAN）在图片生成和半监督学习（SSL）上显示了很强的能力。但是，现有的GAN和SSL有两个问题：（1）生成器和判别器可能不能够同时达到最优；（2）生成器不能控制生成图像的语义信息。这些问题从基础上是来自于GAN的双元公式，其中单一的判别器需要在判断假样本和不考虑标签预测新样本两个任务中分享不兼容的规则。为了解决这些问题，我们提出了三元对抗生成网络（Triple-GAN），其中包括了三个方面：生成器，判别器和分类器。生成器和分类器来识别分布在图片和标签上的条件概率分布，判别器单独关注于判断假的图片-标签对。我们设计了一个兼容的效用来确保生成器和判别器识别到的分布都可以收敛到数据分布。我们在多种数据集上的结果显示了Triple-GAN作为一个统一的模型可以同时的（1）得到最先进的深度生成模型的分类结果；（2）解决输入的类别和风格问题并且通过在隐空间内类别条件限制下的内插能够平滑地转换到数据空间。</p>
<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>TripleGAN解决了两个传统GAN的痛点：（1）G和D不能同时达到最优；（2）G不能够理解语义。其中（1）的原因是来自于two-player formulation，单一的D同时负担了判别和预测两个任务。（2）的原因是传统GAN中D只接收到了单一的图片信息而不是接收到图片-标签对的信息，同时D在判别的时候，忽略掉了标签信息。所以文章针对这两个痛点提出了Triple-GAN：</p>
<p><img src="Triple-GAN数学推导/TripleGAN.png" alt="TripleGAN"></p>
<p>对整个结构图做一个解释：</p>
<p>$X$表示data，$Y$表示label，$Z$表示noise。</p>
<p>$(X_{l}, Y_{l}) \sim p(x,y)$是原始数据分布，其中$p(x,y) = p(x)p(y|x) = p(y)p(x|y)$。</p>
<p>C：classifier分类器，基于输入的data，预测label，得到条件概率$p_{c}(y|x)$，输出关于$x,y$的分布$p_{c}(x,y)$（$x$为真，$y$为假）。</p>
<p>G：generator生成器，基于输入的label，生成data，得到条件概率$p_{g}(x|y)$，输入关于$x,y$的分布$p_{g}(x,y)$（$x$为假，$y$为真）。</p>
<p>D：discriminator判别器，判断输入的$(x,y)$是否来自真实的数据分布$p(x,y)$。</p>
<h3 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h3><p>像GAN一样，TripleGAN追求的目标是三个部分的分布达到统一，即</p>
<p>$p(x,y) = p_{g}(x,y) = p_{c}(x,y)$。</p>
<p>所以就可以得到：</p>
<p>$\min_{C,G}\max_{D} U(C,G,D) = \mathbb{E}<em>{(x,y) \sim p(x,y)}[\log{D(x,y)}] + \alpha\mathbb{E}</em>{(x,y) \sim p_{c}(x,y)}[\log{(1 - D(x,y))}] + (1 - \alpha)\mathbb{E}<em>{(x,y) \sim p</em>{g}(x,y)}[\log{(1 - D(G(y,z),y))}]$</p>
<p>，其中$\alpha$为平衡生成器和分类器的权重，一般取 $\frac{1}{2}$。</p>
<p>因为不能够保证$p(x,y) = p_{g}(x,y) = p_{c}(x,y)$是唯一的极小值点，所以在训练中加入了standard supervised loss $R_{L}$和discriminative loss $R_{\rho}$，其中：</p>
<p>$R_{L} = D_{KL}(p(x,y)||p_{c}(x,y)) =\iint_{(x,y)}p(x,y)\log{\frac{p((x,y)}{p_{c}(x,y)}}dxdy = \iint_{(x,y)}p(x,y)\log{\frac{p(x)p(y|x)}{p_{c}(x)p_{c}(y|x)}}dxdy$</p>
<p>因为判别器和分类器输入的图片都是真实的，所以$p(x) = p_{c}(x)​$，所以</p>
<p>$R_{L} = \iint_{(x,y)}p(x,y)\log{p(y|x)}dxdy - \iint_{(x,y)}p(x,y)\log{p_{c}(y|x)}dxdy = -\mathbb{E}<em>{(x,y) \sim p(x,y)}[\log{(p</em>{c}(y|x))}]$。</p>
<p>下面来计算$R_{\rho}$：</p>
<p>$R_{\rho} = D_{KL}(p_{g}(x,y)||p_{c}(x,y)) + H_{p_{g}}(y|x) - D_{KL}(p_{g}(x)||p(x))$，</p>
<p>因为$\frac{p_{g}(x,y)}{p_{c}(x,y)}$未知，所以$D_{KL}(p_{g}(x,y)||p_{c}(x,y))$无法计算，所以加上一个与C无关的后项，对收敛结果不会产生影响，则：</p>
<p>$R_{\rho} = \iint p_{g}(x,y)\log{\frac{p_{g}(x,y)}{p_{c}(x,y)}} + p_{g}(x,y)\log{\frac{1}{p_{g}(y|x)}}dxdy - \int p_{g}(x)\log{\frac{p_{g}(x)}{p(x)}}dx \\ =\iint p_{g}(x,y)\log{\frac{p_{g}(x,y)}{p_{c}(x,y)p_{g}(x,y)}}dxdy - \iint p_{g}(x,y)\log{\frac{p_{g}(x)}{p(x)}}dxdy \\ =\iint p_{g}(x,y)\log{\frac{p_{g}(x,y)p(x)}{p_{c}(x,y)p_{g}(y|x)p_{g}(x)}}dxdy \\ = -\mathbb{E}<em>{(x,y) \sim p</em>{g}(x,y)}[\log{p_{c}(y|x)}]$</p>
<p>所以整个的训练过程如下：</p>
<p><img src="Triple-GAN数学推导/tripleGanAlg.png" alt="TripleGAN"></p>
<h3 id="几个证明"><a href="#几个证明" class="headerlink" title="几个证明"></a>几个证明</h3><h4 id="1，如何证明D存在最优解为-D-C-G-x-y-frac-p-x-y-p-x-y-p-alpha-x-y-，其中-p-alpha-x-y-1-alpha-p-g-x-y-alpha-p-c-x-y"><a href="#1，如何证明D存在最优解为-D-C-G-x-y-frac-p-x-y-p-x-y-p-alpha-x-y-，其中-p-alpha-x-y-1-alpha-p-g-x-y-alpha-p-c-x-y" class="headerlink" title="1，如何证明D存在最优解为$D_{C,G}^{*}(x,y) = \frac{p(x,y)}{p(x,y)+p_{\alpha}(x,y)}$，其中$p_{\alpha}(x,y) = (1 - \alpha)p_{g}(x,y)+\alpha p_{c}(x,y)$?"></a>1，如何证明D存在最优解为$D_{C,G}^{*}(x,y) = \frac{p(x,y)}{p(x,y)+p_{\alpha}(x,y)}$，其中$p_{\alpha}(x,y) = (1 - \alpha)p_{g}(x,y)+\alpha p_{c}(x,y)$?</h4><p>$U(C,G,D) = \iint p(x,y)\log{D(x,y)}dxdy + (1 - \alpha)\iint p(y)p_{z}(z)\log{1 - D(G(z,y),y)}dydz + \alpha \iint p(x)p_{c}(y|x)\log{(1-D(x,y))}dxdy \\ = \iint p(x,y)\log{D(x,y)}dxdy + (1 - \alpha) \iint p(y)p_{g}(x|y)\log{(1-D(x,y))}dxdy +  \alpha \iint p_{c}(x,y)\log{(1-D(x,y))}dxdy \\ =\iint p(x,y)\log{D(x,y)}dxdy + \iint p_{\alpha}(x,y)\log{(1-D(x,y))}dydx \\ = f(D(x,y))$</p>
<p>以下求导求极值的方法和上一篇文章中GAN的证明相同。所以易证：$D_{C,G}^{*}(x,y) = \frac{p(x,y)}{p(x,y)+p_{\alpha}(x,y)}$。</p>
<h4 id="2，如何证明当且仅当-p-x-y-p-alpha-x-y-时，C和G有最优解？"><a href="#2，如何证明当且仅当-p-x-y-p-alpha-x-y-时，C和G有最优解？" class="headerlink" title="2，如何证明当且仅当$p(x,y) = p_{\alpha}(x,y)$时，C和G有最优解？"></a>2，如何证明当且仅当$p(x,y) = p_{\alpha}(x,y)$时，C和G有最优解？</h4><p>基本证明过程同GAN，只是将GAN证明中的$p_{g}(x)$换成了$p_{\alpha}(x,y)$，最后得到结论：</p>
<p>$V(C,G) = -\log{4} + 2 \cdot JSD(p(x,y)||p_{\alpha}(x,y))$。</p>
<h4 id="3，如何证明当且仅当C和G有最优解时，-p-x-p-c-x-p-g-x-且-p-y-p-c-y-p-g-y"><a href="#3，如何证明当且仅当C和G有最优解时，-p-x-p-c-x-p-g-x-且-p-y-p-c-y-p-g-y" class="headerlink" title="3，如何证明当且仅当C和G有最优解时，$p(x) = p_{c}(x) = p_{g}(x)$且$p(y) = p_{c}(y) = p_{g}(y)$?"></a>3，如何证明当且仅当C和G有最优解时，$p(x) = p_{c}(x) = p_{g}(x)$且$p(y) = p_{c}(y) = p_{g}(y)$?</h4><p>因为$p(x,y) = p_{\alpha}(x,y) = (1 - \alpha)p_{g}(x,y)+\alpha p_{c}(x,y)$</p>
<p>所以$\int p(x,y)dx = (1 - \alpha)\int p_{g}(x,y)dx + \alpha \int p_{c}(x,y)dx$</p>
<p>即$p(y) = (1-\alpha)p_{g}(y) + \alpha p_{c}(y)$，</p>
<p>当$\alpha = \frac{1}{2}$时，$p(y) = p_{c}(y) = p_{g}(y)$。</p>
<p>$p(x)$的证明同理。</p>
